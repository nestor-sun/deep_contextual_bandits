import sys
sys.path.append('D:/study/gumd/UMD_course/machine learning guarantees and analyses/deep_contextual_bandits/deep_contextual/exploitation_exploration')

import json
from ts import ts
from ucb import ucb_bandit
from epsilon_greedy import epsilon_greedy
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn


data_path = 'D:/study/gumd/UMD_course/machine learning guarantees and analyses/deep_contextual_bandits/data/'
file_name = 'U0001.json'


def load_nn_model_and_optimizer():
    learning_rate = 0.0001
    path = 'D:/study/gumd/UMD_course/machine learning guarantees and analyses/deep_contextual_bandits/deep_contextual/model/'
    model = torch.load(path + 'model.dat')
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    return model, optimizer, criterion


data = json.load(open(data_path + file_name, 'r'))
ratings = list(data.values())

num_of_episodes = 100
number_of_iters = 1000
epsilon = 0.1

eg = epsilon_greedy(epsilon, number_of_iters, ratings)
ucb = ucb_bandit(1, number_of_iters, ratings)
ts = ts(number_of_iters, ratings)

eg_reward_list = []
ucb_reward_list = []
ts_reward_list = []

for i in range(num_of_episodes):
    print(i)
    eg.reset()
    ucb.reset()
    ts.reset()

    eg.run()
    ucb.run()
    ts.run()

    eg_reward_list.append(eg.reward)
    ts_reward_list.append(ts.reward)
    ucb_reward_list.append(ucb.reward)

ucb_rewards = np.mean(ucb_reward_list, axis=0)
ts_rewards = np.mean(ts_reward_list, axis=0)
eg_rewards = np.mean(eg_reward_list, axis=0)


# plt.figure()
plt.plot(ucb_rewards, label='UCB Bandit')
plt.plot(eg_rewards, label="$\epsilon={}$".format(eg.epsilon))
plt.plot(ts_rewards, label='TS')

plt.legend()
plt.xlabel("Iterations")
plt.ylabel("Average Reward")
plt.title("Average rewards for UCB, TS and $\epsilon$-Greedy Bandits")
plt.show()
