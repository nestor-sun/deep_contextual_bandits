import numpy as np
import random


class ts:
    '''
    Thompson Bandit

    Inputs
    ============================================
    k: number of arms (int)
    c:
    iters: number of steps (int)
    mu: set the average rewards for each of the k-arms.
        Set to "random" for the rewards to be selected from
        a normal distribution with mean = 0.
        Set to "sequence" for the means to be ordered from
        0 to k-1.
        Pass a list or array of length = k for user-defined
        values.
    '''

    def __init__(self, iters, ratings):
        # Number of arms
        self.k = len(ratings)
        # Number of iterations
        self.iters = iters
        # Step count
        self.n = 1
        # Step count for each arm
        self.k_n = np.ones(self.k)
        # Total mean reward
        self.mean_reward = 0
        self.reward = np.zeros(iters)
        # Mean reward for each arm
        self.k_reward_list = [[] for i in range(self.k)]
        # ads rating list
        self.ratings = ratings

    def pull(self):
        choice = np.argmax([np.random.normal(np.mean(self.k_reward_list[i]), np.var(self.k_reward_list[i])) for i in range(self.k)])
        # print(choice)
        reward = random.choice(self.ratings[choice])

        # Update counts
        self.n += 1
        self.k_n[choice] += 1

        # Update total
        self.mean_reward = self.mean_reward + (reward - self.mean_reward) / self.n

        # Update results for a_k
        # self.k_reward[choice] = self.k_reward[choice] + (reward - self.k_reward[choice]) / self.k_n[choice]
        self.k_reward_list[choice].append(reward)

    def run(self):
        for i in range(self.iters):
            self.pull()
            self.reward[i] = self.mean_reward
            # print(np.mean(self.reward))
            # print(self.k_reward_list)

    def reset(self):
        # Resets results while keeping settings
        self.n = 1
        self.k_n = np.ones(self.k)
        self.mean_reward = 0
        self.reward = np.zeros(self.iters)
        self.k_reward = np.zeros(self.k)


# data_path = 'D:/study/gumd/UMD_course/machine learning guarantees and analyses/deep_contextual_bandits/data/'
# file_name = 'U0001.json'
#
# data = json.load(open(data_path + file_name, 'r'))
# ratings = list(data.values())
#
# iters = 5000

# Initialize bandits
# ts= ts(len(list(data.keys())), iters, ratings)
# ts.run()
# best_choice = np.argmax(ucb.k_reward)
# print(best_choice)
# print(list(data.keys())[best_choice])
